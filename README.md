## ğŸ¤ åä½œè€…

**æˆ‘ä»¬æ¬¢è¿ç¤¾åŒºåšå‡ºè´¡çŒ®ï¼Œä»¥å¸®åŠ©å¢å¼º GraphRAG Local Ollamaï¼è¯·å‚é˜…æˆ‘ä»¬çš„[è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)ï¼Œäº†è§£æœ‰å…³å¦‚ä½•å‚ä¸çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚**

# ğŸš€ GraphRAG-Local-Ollama - çŸ¥è¯†å›¾è°±

ä½¿ç”¨Ollamaåœ¨æœ¬åœ°è¿è¡ŒGraphRAG

## ğŸ“„ å‚è€ƒè®ºæ–‡

æœ‰å…³ GraphRAG å®ç°çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[GraphRAG è®ºæ–‡](https://arxiv.org/pdf/2404.16130).

**Paper Abstract**

The use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs)to answer questions over private and/or previously unseen document collections.However, RAG fails on global questions directed at an entire text corpus, suchas â€œWhat are the main themes in the dataset?â€, since this is inherently a queryfocused summarization (QFS) task, rather than an explicit retrieval task. PriorQFS methods, meanwhile, fail to scale to the quantities of text indexed by typicalRAG systems. To combine the strengths of these contrasting methods, we proposea Graph RAG approach to question answering over private text corpora that scaleswith both the generality of user questions and the quantity of source text to be indexed. Our approach uses an LLM to build a graph-based text index in two stages:first to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely-related entities. Given aquestion, each community summary is used to generate a partial response, beforeall partial responses are again summarized in a final response to the user. For aclass of global sensemaking questions over datasets in the 1 million token range,we show that Graph RAG leads to substantial improvements over a naÂ¨Ä±ve RAGbaseline for both the comprehensiveness and diversity of generated answers. 

## ğŸ“¦ å®‰è£…ä¸è®¾ç½®

æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è®¾ç½®æ­¤å­˜å‚¨åº“å¹¶å°† GraphRag ä¸ Ollama æä¾›çš„æœ¬åœ°æ¨¡å‹ä¸€èµ·ä½¿ç”¨ï¼š


1. **åˆ›å»ºå¹¶æ¿€æ´»æ–°çš„ conda ç¯å¢ƒï¼šï¼ˆè¯·ä½¿ç”¨ç»™å®šçš„ python ç‰ˆæœ¬ 3.10 ä»¥é¿å…å‡ºç°é”™è¯¯ï¼‰**
    ```bash
    conda create -n graphrag-ollama-local python=3.10
    conda activate graphrag-ollama-local
    ```
    condaæŒ‡ä»¤é€šè¿‡å®‰è£…Anaconda, Miniconda, conda-forgeç­‰å‡å¯ï¼Œæˆ‘å®‰è£…äº†Anaconda3

2. **å®‰è£… Ollamaï¼š**
    - è¯·è®¿é—®[Ollama å®˜ç½‘](https://ollama.com/)è·å–å®‰è£…è¯´æ˜
    - æˆ–è€…è¿è¡Œï¼š
    ```bash
    curl -fsSL https://ollama.com/install.sh | sh #ollama for linux
    pip install ollama
    ```

3. **ä½¿ç”¨ Ollama ä¸‹è½½æ‰€éœ€çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ä» llm çš„ï¼ˆmistralã€gemma2ã€qwen2ï¼‰å’Œ Ollama ä¸‹æä¾›çš„ä»»ä½•åµŒå…¥æ¨¡å‹ä¸­è¿›è¡Œé€‰æ‹©ï¼š**
    ```bash
    ollama pull mistral  #llm
    ollama pull nomic-embed-text  #embedding
    ```

4. **å…‹éš†å­˜å‚¨åº“ï¼š**
    ```bash
    git clone https://github.com/Wusiyuan0330/graphrag-ollama.git
    ```

5. **å¯¼èˆªåˆ°ç›®å½•**
    ```bash
    cd graphrag-local-ollama/
    ```

6. **å®‰è£… graphrag åŒ… **è¿™æ˜¯æœ€é‡è¦çš„ä¸€æ­¥ï¼š**
    ```bash
    pip install -e .
    ```


7. **åˆ›å»ºæ‰€éœ€çš„inputç›®å½•ï¼šå­˜å‚¨å®éªŒæ•°æ®å’Œç»“æœ - ./ragtest**
    ```bash
    mkdir -p ./ragtest/input
    ```
    windowså‘½ä»¤æç¤ºç¬¦ä¸­éœ€è¦ç”¨"mkdir ragtest\input"
    
8. **å°†ç¤ºä¾‹æ•°æ®æ–‡ä»¶å¤¹ input/ å¤åˆ¶åˆ° ./ragtestã€‚Input/ åŒ…å«è¿è¡Œè®¾ç½®çš„ç¤ºä¾‹æ•°æ®ã€‚æ‚¨å¯ä»¥åœ¨æ­¤å¤„ä»¥ .txt æ ¼å¼æ·»åŠ è‡ªå·±çš„æ•°æ®ã€‚**
    ```bash
    cp input/* ./ragtest/input
    ```
    windowså‘½ä»¤æç¤ºç¬¦ä¸­éœ€è¦ç”¨"copy input\* .\ragtest\input"
    
9. **åˆå§‹åŒ–./ragtest æ–‡ä»¶å¤¹ä»¥åˆ›å»ºæ‰€éœ€çš„æ–‡ä»¶ï¼š**
    ```bash
    python -m graphrag.index --init --root ./ragtest
    ```

10. **ç§»åŠ¨ settings.yaml æ–‡ä»¶ï¼Œè¿™æ˜¯ä½¿ç”¨ ollama æœ¬åœ°æ¨¡å‹é…ç½®çš„ä¸»è¦é¢„å®šä¹‰é…ç½®æ–‡ä»¶ï¼š**
    ```bash
    cp settings.yaml ./ragtest
    ```

ç”¨æˆ·å¯ä»¥é€šè¿‡æ›´æ”¹æ¨¡å‹è¿›è¡Œå®éªŒã€‚llm æ¨¡å‹éœ€è¦è¯­è¨€æ¨¡å‹ï¼Œå¦‚ llama3ã€mistralã€phi3 ç­‰ï¼Œè€ŒåµŒå…¥æ¨¡å‹éƒ¨åˆ†éœ€è¦åµŒå…¥æ¨¡å‹ï¼Œå¦‚ mxbai-embed-largeã€nomic-embed-text ç­‰ï¼Œè¿™äº›æ¨¡å‹ç”± Ollama æä¾›ã€‚æ‚¨å¯ä»¥åœ¨æ­¤å¤„https://ollama.com/libraryæ‰¾åˆ° Ollama æä¾›çš„å®Œæ•´æ¨¡å‹åˆ—è¡¨ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥åœ¨æœ¬åœ°éƒ¨ç½²ã€‚LLM çš„é»˜è®¤ API åŸºæœ¬ URL ä¸ºhttp://localhost:11434/v1ï¼ŒåµŒå…¥çš„é»˜è®¤ API åŸºæœ¬ URL ä¸ºhttp://localhost:11434/apiï¼Œå› æ­¤å®ƒä»¬è¢«æ·»åŠ åˆ°ç›¸åº”çš„éƒ¨åˆ†ã€‚

![LLM Configuration](<Screenshot 2024-07-09 at 3.34.31â€¯AM-1.png>)

![Embedding Configuration](<Screenshot 2024-07-09 at 3.36.28â€¯AM.png>)

11. **è¿è¡Œç´¢å¼•ï¼Œåˆ›å»ºå›¾è¡¨ï¼š**
    ```bash
    python -m graphrag.index --root ./ragtest
    ```

12. **è¿è¡ŒæŸ¥è¯¢ï¼šä»…æ”¯æŒå…¨å±€æ–¹æ³•**
    ```bash
    python -m graphrag.query --root ./ragtest --method global "What is machine learning?"
    ```
    å‡†å¤‡ä¿®æ”¹ä»¥æ”¯æŒæœ¬åœ°(local)æ–¹æ³•

**å¯ä»¥ä¿å­˜å›¾è¡¨ï¼Œå¹¶é€šè¿‡åœ¨ settings.yaml ä¸­å°† graphml æ›´æ”¹ä¸ºâ€œtrueâ€æ¥è¿›ä¸€æ­¥ç”¨äºå¯è§†åŒ–ï¼š**
    
    snapshots:
    graphml: true
    
**ä¸ºäº†å¯è§†åŒ–ç”Ÿæˆçš„ graphml æ–‡ä»¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼šhttps://gephi.org/users/download/æˆ– repo visualize-graphml.py ä¸­æä¾›çš„è„šæœ¬ï¼š**

å°†.graphml æ–‡ä»¶çš„è·¯å¾„ä¼ é€’ç»™ visualize-graphml.py ä¸­çš„ä»¥ä¸‹è¡Œï¼š

    graph = nx.read_graphml('output/20240708-161630/artifacts/summarized_graph.graphml') 

13. **å¯è§†åŒ–.graphmlï¼š**

    ```bash
    python visualize-graphml.py
    ```



## å¼•ç”¨

- Original GraphRAG repository by Microsoft: [GraphRAG](https://github.com/microsoft/graphrag)
- Ollama: [Ollama](https://ollama.com/)
- graphrag-local-ollamaï¼šhttps://github.com/TheAiSingularity/graphrag-local-ollama
---
